{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import skimage.io as io\n",
    "import os, sys\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Use second GPU -- change if you want to use a first one\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = '1'\n",
    "\n",
    "# Add a path to a custom fork of TF-Slim\n",
    "# Get it from here:\n",
    "# https://github.com/warmspringwinds/models/tree/fully_conv_vgg\n",
    "sys.path.append(\"/home/shou/network/tf-models/research/slim\")\n",
    "\n",
    "# Add path to the cloned library\n",
    "sys.path.append(\"/home/shou/network/fcn/tf-image-segmentation\")\n",
    "\n",
    "checkpoints_dir = '/home/shou/network/checkpoints'\n",
    "log_folder = '/home/shou/network/log_folder'\n",
    "\n",
    "\n",
    "slim = tf.contrib.slim\n",
    "vgg_checkpoint_path = os.path.join(checkpoints_dir, 'vgg_16.ckpt')\n",
    "\n",
    "from tf_image_segmentation.utils.tf_records import read_tfrecord_and_decode_into_image_annotation_pair_tensors\n",
    "from tf_image_segmentation.models.fcn_32s import FCN_32s, extract_vgg_16_mapping_without_fc8\n",
    "\n",
    "from tf_image_segmentation.utils.pascal_voc import pascal_segmentation_lut\n",
    "\n",
    "from tf_image_segmentation.utils.training import get_valid_logits_and_labels\n",
    "\n",
    "from tf_image_segmentation.utils.augmentation import (distort_randomly_image_color,\n",
    "                                                      flip_randomly_left_right_image_with_annotation,\n",
    "                                                      scale_randomly_image_with_annotation_with_fixed_size_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 255]\n"
     ]
    }
   ],
   "source": [
    "image_train_size = [384, 384]\n",
    "number_of_classes = 2\n",
    "# tfrecord_filename = '/home/shou/network/island/pascal_augmented_train_pas.tfrecords'\n",
    "tfrecord_filename = '/home/shou/tif/pascal_augmented_train_island.tfrecords'\n",
    "pascal_voc_lut = pascal_segmentation_lut(number_of_classes)\n",
    "class_labels = pascal_voc_lut.keys()\n",
    "print(class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/shou/network/fcn/tf-image-segmentation/tf_image_segmentation/utils/augmentation.py:36: calling cond (from tensorflow.python.ops.control_flow_ops) with fn2 is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "fn1/fn2 are deprecated in favor of the true_fn/false_fn arguments.\n",
      "WARNING:tensorflow:From /home/shou/network/fcn/tf-image-segmentation/tf_image_segmentation/utils/augmentation.py:36: calling cond (from tensorflow.python.ops.control_flow_ops) with fn1 is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "fn1/fn2 are deprecated in favor of the true_fn/false_fn arguments.\n",
      "WARNING:tensorflow:From /home/shou/network/fcn/tf-image-segmentation/tf_image_segmentation/utils/augmentation.py:40: calling cond (from tensorflow.python.ops.control_flow_ops) with fn2 is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "fn1/fn2 are deprecated in favor of the true_fn/false_fn arguments.\n",
      "WARNING:tensorflow:From /home/shou/network/fcn/tf-image-segmentation/tf_image_segmentation/utils/augmentation.py:40: calling cond (from tensorflow.python.ops.control_flow_ops) with fn1 is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "fn1/fn2 are deprecated in favor of the true_fn/false_fn arguments.\n",
      "WARNING:tensorflow:From <ipython-input-3-cbe8fd03fdef>:40: calling argmax (from tensorflow.python.ops.math_ops) with dimension is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the `axis` argument instead\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Dimension (7) must be in the range [-4, 4), where 4 is the number of dimensions in the input. for 'ArgMax' (op: 'ArgMax') with input shapes: [?,?,?,?], [] and with computed input tensors: input[1] = <7>.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-cbe8fd03fdef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0mcross_entropy_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcross_entropies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupsampled_logits_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdimension\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0mprobabilities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupsampled_logits_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/util/deprecation.pyc\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    294\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m               instructions)\n\u001b[0;32m--> 296\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m     return tf_decorator.make_decorator(func, new_func, 'deprecated',\n\u001b[1;32m    298\u001b[0m                                        _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_ops.pyc\u001b[0m in \u001b[0;36margmax\u001b[0;34m(input, axis, name, dimension, output_type)\u001b[0m\n\u001b[1;32m    201\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marg_max\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_math_ops.pyc\u001b[0m in \u001b[0;36marg_max\u001b[0;34m(input, dimension, output_type, name)\u001b[0m\n\u001b[1;32m    187\u001b[0m   \"\"\"\n\u001b[1;32m    188\u001b[0m   result = _op_def_lib.apply_op(\"ArgMax\", input=input, dimension=dimension,\n\u001b[0;32m--> 189\u001b[0;31m                                 output_type=output_type, name=name)\n\u001b[0m\u001b[1;32m    190\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.pyc\u001b[0m in \u001b[0;36mapply_op\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    765\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    766\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 767\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    768\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[1;32m   2630\u001b[0m                     original_op=self._default_original_op, op_def=op_def)\n\u001b[1;32m   2631\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcompute_shapes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2632\u001b[0;31m       \u001b[0mset_shapes_for_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2633\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2634\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_record_op_seen_by_control_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mset_shapes_for_outputs\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   1909\u001b[0m       \u001b[0mshape_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1910\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1911\u001b[0;31m   \u001b[0mshapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1912\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshapes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1913\u001b[0m     raise RuntimeError(\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mcall_with_requiring\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   1859\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1860\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1861\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcall_cpp_shape_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequire_shape_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1862\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1863\u001b[0m   \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/common_shapes.pyc\u001b[0m in \u001b[0;36mcall_cpp_shape_fn\u001b[0;34m(op, require_shape_fn)\u001b[0m\n\u001b[1;32m    593\u001b[0m     res = _call_cpp_shape_fn_impl(op, input_tensors_needed,\n\u001b[1;32m    594\u001b[0m                                   \u001b[0minput_tensors_as_shapes_needed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m                                   require_shape_fn)\n\u001b[0m\u001b[1;32m    596\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m       \u001b[0;31m# Handles the case where _call_cpp_shape_fn_impl calls unknown_shape(op).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/common_shapes.pyc\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, require_shape_fn)\u001b[0m\n\u001b[1;32m    657\u001b[0m       \u001b[0mmissing_shape_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 659\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mmissing_shape_fn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Dimension (7) must be in the range [-4, 4), where 4 is the number of dimensions in the input. for 'ArgMax' (op: 'ArgMax') with input shapes: [?,?,?,?], [] and with computed input tensors: input[1] = <7>."
     ]
    }
   ],
   "source": [
    "filename_queue = tf.train.string_input_producer(\n",
    "    [tfrecord_filename], num_epochs=2)\n",
    "\n",
    "image, annotation = read_tfrecord_and_decode_into_image_annotation_pair_tensors(filename_queue)\n",
    "\n",
    "# Various data augmentation stages\n",
    "image, annotation = flip_randomly_left_right_image_with_annotation(image, annotation)\n",
    "\n",
    "# image = distort_randomly_image_color(image)\n",
    "\n",
    "resized_image, resized_annotation = scale_randomly_image_with_annotation_with_fixed_size_output(image, annotation, image_train_size)\n",
    "\n",
    "\n",
    "resized_annotation = tf.squeeze(resized_annotation)\n",
    "\n",
    "image_batch, annotation_batch = tf.train.shuffle_batch( [resized_image, resized_annotation],\n",
    "                                             batch_size=1,\n",
    "                                             capacity=3000,\n",
    "                                             num_threads=2,\n",
    "                                             min_after_dequeue=1000)\n",
    "\n",
    "upsampled_logits_batch, vgg_16_variables_mapping = FCN_32s(image_batch_tensor=image_batch,\n",
    "                                                           number_of_classes=number_of_classes,\n",
    "                                                           is_training=True)\n",
    "\n",
    "\n",
    "valid_labels_batch_tensor, valid_logits_batch_tensor = get_valid_logits_and_labels(annotation_batch_tensor=annotation_batch,\n",
    "                                                                                     logits_batch_tensor=upsampled_logits_batch,\n",
    "                                                                                    class_labels=class_labels)\n",
    "\n",
    "\n",
    "\n",
    "cross_entropies = tf.nn.softmax_cross_entropy_with_logits(logits=valid_logits_batch_tensor,\n",
    "                                                          labels=valid_labels_batch_tensor)\n",
    "\n",
    "# Normalize the cross entropy -- the number of elements\n",
    "# is different during each step due to mask out regions\n",
    "cross_entropy_sum = tf.reduce_mean(cross_entropies)\n",
    "\n",
    "pred = tf.argmax(upsampled_logits_batch, dimension=3)\n",
    "\n",
    "probabilities = tf.nn.softmax(upsampled_logits_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"adam_vars\"):\n",
    "    train_step = tf.train.AdamOptimizer(learning_rate=0.000001).minimize(cross_entropy_sum)\n",
    "\n",
    "\n",
    "# Variable's initialization functions\n",
    "vgg_16_without_fc8_variables_mapping = extract_vgg_16_mapping_without_fc8(vgg_16_variables_mapping)\n",
    "\n",
    "\n",
    "init_fn = slim.assign_from_checkpoint_fn(model_path=vgg_checkpoint_path,\n",
    "                                         var_list=vgg_16_without_fc8_variables_mapping)\n",
    "\n",
    "global_vars_init_op = tf.global_variables_initializer()\n",
    "\n",
    "tf.summary.scalar('cross_entropy_loss', cross_entropy_sum)\n",
    "\n",
    "merged_summary_op = tf.summary.merge_all()\n",
    "\n",
    "summary_string_writer = tf.summary.FileWriter(log_folder)\n",
    "\n",
    "# Create the log folder if doesn't exist yet\n",
    "if not os.path.exists(log_folder):\n",
    "     os.makedirs(log_folder)\n",
    "    \n",
    "#The op for initializing the variables.\n",
    "local_vars_init_op = tf.local_variables_initializer()\n",
    "\n",
    "combined_op = tf.group(local_vars_init_op, global_vars_init_op)\n",
    "\n",
    "# We need this to save only model variables and omit\n",
    "# optimization-related and other variables.\n",
    "model_variables = slim.get_model_variables()\n",
    "saver = tf.train.Saver(model_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session()  as sess:\n",
    "    \n",
    "    sess.run(combined_op)\n",
    "    init_fn(sess)\n",
    "\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(coord=coord)\n",
    "    \n",
    "    # 10 epochs\n",
    "    for i in xrange(2* 2):\n",
    "    \n",
    "        cross_entropy, summary_string, _ = sess.run([ cross_entropy_sum,\n",
    "                                                      merged_summary_op,\n",
    "                                                      train_step ])\n",
    "        \n",
    "        print(str(i) + \" Current loss: \" + str(cross_entropy))\n",
    "        \n",
    "        summary_string_writer.add_summary(summary_string, i)\n",
    "        \n",
    "        if i % 5 == 0:\n",
    "            save_path = saver.save(sess, \"/home/shou/tif/model_fcn32s.ckpt\")\n",
    "            print(\"Model saved in file: %s\" % save_path)\n",
    "            \n",
    "        if cross_entropy < 0.1:\n",
    "            print('the last loss: ' + str(cross_entropy))\n",
    "            break\n",
    "\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)\n",
    "    \n",
    "    save_path = saver.save(sess, \"/home/shou/tif/model_fcn32s.ckpt\")\n",
    "    print(\"Model saved in file: %s\" % save_path)\n",
    "    \n",
    "summary_string_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
